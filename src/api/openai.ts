// src/api/openai.ts

import OpenAI from 'openai';
import { env } from '../config/env';
import { logger } from '../utils/logger';

logger.info('[openai] Inicializando cliente OpenAI');

export const openai = new OpenAI({
  apiKey: env.OPENAI_KEY,
});

/**
 * Wrapper para cria√ß√£o de chat completion com logs detalhados e fallback de par√¢metros.
 *
 * @param messages - Lista de mensagens no formato esperado pela OpenAI
 * @param options - Configura√ß√µes opcionais (modelo, temperatura, est√°gio do funil)
 * @returns Completion gerada pela API OpenAI
 */
export async function createChatCompletion(
  messages: OpenAI.Chat.ChatCompletionMessageParam[],
  options?: { model?: string; temperature?: number; funnelStage?: string }
) {
  try {
    const model = options?.model || env.OPENAI_MODEL || 'gpt-4';

    // Estrat√©gia para log de origem da temperatura
    let temperature: number;
    let origem: string;

    if (typeof options?.temperature === 'number') {
      temperature = options.temperature;
      origem = 'for√ßada via par√¢metro options';
    } else if (env.OPENAI_TEMPERATURE) {
      temperature = Number(env.OPENAI_TEMPERATURE);
      origem = 'vinda do .env ou env.ts';
    } else {
      temperature = 0.7;
      origem = 'valor padr√£o hardcoded (0.7)';
    }

    // üîç Sugest√£o de l√≥gica futura baseada em etapas do funil
    // if (options?.funnelStage === 'levantamento') temperature = 0.9;
    // if (options?.funnelStage === 'negociacao') temperature = 0.5;
    // if (options?.funnelStage === 'fechamento') temperature = 0.3;

    logger.debug('[openai] Criando chat completion', {
      model,
      temperature,
      origem,
      mensagens: messages.map(m => ({
        role: m.role,
        preview: typeof m.content === 'string' ? m.content.slice(0, 60) : '[n√£o string]',
      })),
    });

    const completion = await openai.chat.completions.create({
      model,
      temperature,
      messages,
    });

    const botText = completion.choices?.[0]?.message?.content?.trim() || '[sem resposta]';

    logger.info('[openai] ü§ñ Resposta da IA recebida', {
      texto: botText.substring(0, 300) + (botText.length > 300 ? '...' : ''),
    });

    logger.debug('[openai] Completion metadata', {
      finish_reason: completion.choices?.[0]?.finish_reason,
      usage: completion.usage,
    });

    return completion;
  } catch (error: unknown) {
    logger.error('[openai] Erro na cria√ß√£o do chat completion', {
      error: error instanceof Error ? error.message : error,
    });
    throw error;
  }
}
